{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed005193",
   "metadata": {},
   "source": [
    "### YOLO v1 Architecture and Functionality\n",
    "* The input image is divided into an S Ã— S grid of cells. Each grid cell is responsible for predicting B bounding boxes and their confidence scores, as well as C class probabilities. \n",
    "\n",
    "* The bounding box predictions include the coordinates (x, y) of the box center relative to the grid cell, the width (w) and height (h) of the box relative to the entire image, and a confidence score that indicates how certain the model is that the box contains an object.\n",
    "* Thus for each grid cell, the model predicts a total of B * 5 + C values.\n",
    "* Confidence Score = Pr(Object) * IOU(pred, truth) (It is for the bounding box)\n",
    "* Class Probabilities = Pr(Class_i | Object) (It is for the grid cell)\n",
    "* Ouput Tensor Shape = S x S x (B * 5 + C)  \n",
    "\n",
    "* If a cell contains a ground-truth object (object center in cell), among the B box predictors that cell has, the one with highest IoU (with that ground truth box) is chosen as responsible. The loss is only calculated for that bounding box predictor. The other bounding box predictors in that cell are ignored for that object.\n",
    "\n",
    "* The loss function used in YOLOv1 is a combination of multiple components that measure the accuracy of the model's predictions. These components include:\n",
    "  - Localization Loss: Measures the error in the predicted bounding box coordinates (x, y, w, h) for the boxes responsible for detecting objects.\n",
    "  - Confidence Loss: Measures the error in the confidence scores for both the boxes that contain objects and those that do not.\n",
    "  - Classification Loss: Measures the error in the predicted class probabilities for the grid cells that contain objects.\n",
    "\n",
    "* During inference, the model outputs a tensor of shape S x S x (B * 5 + C) for each input image. This tensor contains the predicted bounding box coordinates, confidence scores, and class probabilities for each grid cell.\n",
    "\n",
    "* Non-Maximum Suppression (NMS) is applied to filter out overlapping bounding boxes and retain only the most confident ones for each detected object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee2de6b",
   "metadata": {},
   "source": [
    "## for Object Detection for Gate and Flare Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50f8616",
   "metadata": {},
   "source": [
    "### Training Code   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2352f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "MODEL_PATH = \"/Users/mohammadbilal/Documents/Projects/GateDetection/Models/yolo_v8m.pt\"        # path to your trained YOLO .pt file\n",
    "IMAGE_PATH = \"GateDetection/assets/gate+flare-2022.jpg\"       # path to input image\n",
    "SAVE_PATH = \"GateDetection/assets/output.jpg\"      # output image path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af9f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(\n",
    "    data='Dataset/data.yaml',\n",
    "    save=True,\n",
    "    epochs=100, \n",
    "    imgsz=480, # Resolution of the image\n",
    "    batch=8, # Batch Size\n",
    "    lr0=0.001,\n",
    "    lrf=0.1, # Final learning rate multiplier\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005,\n",
    "    augment=True,\n",
    "    workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9410df8",
   "metadata": {},
   "source": [
    "### Inference Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af40224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Image Inference\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "results = model(\n",
    "    IMAGE_PATH,\n",
    "    conf=0.25,        \n",
    "    iou=0.45,         \n",
    "    imgsz=640,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "annotated_img = results[0].plot()\n",
    "cv2.imwrite(SAVE_PATH, annotated_img)\n",
    "\n",
    "cv2.imshow(\"YOLO Detection\", annotated_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Inference completed. Saved at:\", SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eecedc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 153.7ms\n",
      "Speed: 4.4ms preprocess, 153.7ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 156.7ms\n",
      "Speed: 1.2ms preprocess, 156.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 113.5ms\n",
      "Speed: 1.3ms preprocess, 113.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 98.3ms\n",
      "Speed: 1.2ms preprocess, 98.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 93.7ms\n",
      "Speed: 1.1ms preprocess, 93.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 90.0ms\n",
      "Speed: 1.2ms preprocess, 90.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 92.7ms\n",
      "Speed: 1.1ms preprocess, 92.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 95.4ms\n",
      "Speed: 1.6ms preprocess, 95.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Gates, 2 Flares, 88.2ms\n",
      "Speed: 1.2ms preprocess, 88.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Gates, 2 Flares, 85.7ms\n",
      "Speed: 1.0ms preprocess, 85.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Gates, 1 Flare, 89.4ms\n",
      "Speed: 1.1ms preprocess, 89.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Gates, 1 Flare, 91.5ms\n",
      "Speed: 1.0ms preprocess, 91.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Gates, 1 Flare, 89.6ms\n",
      "Speed: 1.1ms preprocess, 89.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Gates, 1 Flare, 86.4ms\n",
      "Speed: 1.0ms preprocess, 86.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Gates, 1 Flare, 86.5ms\n",
      "Speed: 1.0ms preprocess, 86.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 87.0ms\n",
      "Speed: 1.0ms preprocess, 87.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 84.7ms\n",
      "Speed: 1.0ms preprocess, 84.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 90.7ms\n",
      "Speed: 1.0ms preprocess, 90.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Flares, 90.6ms\n",
      "Speed: 1.4ms preprocess, 90.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Flares, 93.8ms\n",
      "Speed: 1.1ms preprocess, 93.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Flares, 88.5ms\n",
      "Speed: 1.2ms preprocess, 88.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Flares, 86.0ms\n",
      "Speed: 1.2ms preprocess, 86.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Flares, 85.6ms\n",
      "Speed: 1.0ms preprocess, 85.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 85.5ms\n",
      "Speed: 1.1ms preprocess, 85.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 88.4ms\n",
      "Speed: 1.0ms preprocess, 88.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 85.1ms\n",
      "Speed: 0.9ms preprocess, 85.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 88.4ms\n",
      "Speed: 1.0ms preprocess, 88.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 86.5ms\n",
      "Speed: 1.1ms preprocess, 86.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 88.7ms\n",
      "Speed: 1.0ms preprocess, 88.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 88.0ms\n",
      "Speed: 1.1ms preprocess, 88.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Flares, 95.9ms\n",
      "Speed: 1.1ms preprocess, 95.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 89.4ms\n",
      "Speed: 1.1ms preprocess, 89.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flare, 93.7ms\n",
      "Speed: 1.0ms preprocess, 93.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flare, 84.3ms\n",
      "Speed: 1.1ms preprocess, 84.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flare, 140.4ms\n",
      "Speed: 1.2ms preprocess, 140.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Flares, 128.0ms\n",
      "Speed: 1.0ms preprocess, 128.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 114.0ms\n",
      "Speed: 1.3ms preprocess, 114.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 108.9ms\n",
      "Speed: 1.3ms preprocess, 108.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flare, 92.8ms\n",
      "Speed: 1.2ms preprocess, 92.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Flares, 87.7ms\n",
      "Speed: 1.0ms preprocess, 87.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 87.1ms\n",
      "Speed: 1.1ms preprocess, 87.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 91.6ms\n",
      "Speed: 1.0ms preprocess, 91.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 91.2ms\n",
      "Speed: 1.1ms preprocess, 91.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 96.2ms\n",
      "Speed: 1.2ms preprocess, 96.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 86.7ms\n",
      "Speed: 1.0ms preprocess, 86.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 89.9ms\n",
      "Speed: 0.9ms preprocess, 89.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 86.9ms\n",
      "Speed: 1.2ms preprocess, 86.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 89.1ms\n",
      "Speed: 1.1ms preprocess, 89.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 94.2ms\n",
      "Speed: 1.2ms preprocess, 94.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 91.6ms\n",
      "Speed: 1.0ms preprocess, 91.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 93.2ms\n",
      "Speed: 1.0ms preprocess, 93.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 117.1ms\n",
      "Speed: 1.3ms preprocess, 117.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 107.3ms\n",
      "Speed: 1.0ms preprocess, 107.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flare, 108.7ms\n",
      "Speed: 1.1ms preprocess, 108.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Flares, 102.0ms\n",
      "Speed: 1.2ms preprocess, 102.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flare, 84.8ms\n",
      "Speed: 1.2ms preprocess, 84.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Gates, 1 Flare, 89.0ms\n",
      "Speed: 1.0ms preprocess, 89.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 89.9ms\n",
      "Speed: 1.2ms preprocess, 89.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 87.3ms\n",
      "Speed: 1.1ms preprocess, 87.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 84.5ms\n",
      "Speed: 1.2ms preprocess, 84.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Gates, 1 Flare, 85.6ms\n",
      "Speed: 1.0ms preprocess, 85.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 85.4ms\n",
      "Speed: 1.0ms preprocess, 85.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 87.2ms\n",
      "Speed: 1.2ms preprocess, 87.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 83.8ms\n",
      "Speed: 1.2ms preprocess, 83.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 85.8ms\n",
      "Speed: 1.5ms preprocess, 85.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 89.0ms\n",
      "Speed: 1.1ms preprocess, 89.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 88.3ms\n",
      "Speed: 1.1ms preprocess, 88.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 95.0ms\n",
      "Speed: 1.3ms preprocess, 95.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 87.0ms\n",
      "Speed: 1.0ms preprocess, 87.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 84.8ms\n",
      "Speed: 1.0ms preprocess, 84.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 82.8ms\n",
      "Speed: 1.3ms preprocess, 82.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 89.8ms\n",
      "Speed: 1.1ms preprocess, 89.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 87.1ms\n",
      "Speed: 1.0ms preprocess, 87.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 87.5ms\n",
      "Speed: 1.1ms preprocess, 87.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 85.1ms\n",
      "Speed: 1.0ms preprocess, 85.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 86.2ms\n",
      "Speed: 1.5ms preprocess, 86.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 96.6ms\n",
      "Speed: 1.2ms preprocess, 96.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 91.2ms\n",
      "Speed: 1.4ms preprocess, 91.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 94.5ms\n",
      "Speed: 1.1ms preprocess, 94.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 109.9ms\n",
      "Speed: 1.5ms preprocess, 109.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 128.5ms\n",
      "Speed: 1.2ms preprocess, 128.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 104.5ms\n",
      "Speed: 1.1ms preprocess, 104.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 110.0ms\n",
      "Speed: 1.0ms preprocess, 110.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 104.0ms\n",
      "Speed: 1.1ms preprocess, 104.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 91.7ms\n",
      "Speed: 1.0ms preprocess, 91.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 94.5ms\n",
      "Speed: 1.2ms preprocess, 94.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 95.8ms\n",
      "Speed: 1.5ms preprocess, 95.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 90.9ms\n",
      "Speed: 1.0ms preprocess, 90.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 88.1ms\n",
      "Speed: 1.3ms preprocess, 88.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 88.8ms\n",
      "Speed: 1.0ms preprocess, 88.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 87.5ms\n",
      "Speed: 1.4ms preprocess, 87.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 2 Flares, 86.8ms\n",
      "Speed: 1.0ms preprocess, 86.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Gates, 1 Flare, 86.7ms\n",
      "Speed: 1.0ms preprocess, 86.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 86.4ms\n",
      "Speed: 1.0ms preprocess, 86.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 83.3ms\n",
      "Speed: 1.1ms preprocess, 83.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Gate, 1 Flare, 87.5ms\n",
      "Speed: 1.0ms preprocess, 87.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Video inference completed. Saved at: /Users/mohammadbilal/Documents/Projects/GateDetection/assets/output_video.mp4\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# For Video Inference\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "VIDEO_PATH = \"/Users/mohammadbilal/Documents/Projects/GateDetection/assets/test_files/test_video.mp4\"\n",
    "SAVE_PATH = \"/Users/mohammadbilal/Documents/Projects/GateDetection/assets/output_video.mp4\"\n",
    "\n",
    "# Load model\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Error opening video file\")\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(SAVE_PATH, fourcc, fps, (width, height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # YOLO inference on frame\n",
    "    results = model(\n",
    "        frame,\n",
    "        conf=0.25,\n",
    "        iou=0.45,\n",
    "        imgsz=640,\n",
    "        device=\"cpu\"\n",
    "    )\n",
    "\n",
    "    # Draw detections\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Write frame\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "    # Optional display\n",
    "    cv2.imshow(\"YOLO Detection\", annotated_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Video inference completed. Saved at:\", SAVE_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
